
HTTP -

1) Identifying resources on the Web -
      * The target of an HTTP request is called a "resource", whose nature isn't defined further; it can be a document, a photo, or anything else. Each resource is identified by a Uniform Resource Identifier (URI) used throughout HTTP for identifying resources.

* URLs and URNs
    URLs - The most common form of URI is the Uniform Resource Locator (URL), which is known as the web address.
    * A URL is composed of different parts, some mandatory and others optional. A more complex example might look like this:
      http://www.example.com:80/path/to/myfile.html?key1=value1&key2=value2#SomewhereInTheDocument

    * URNs - A Uniform Resource Name (URN) is a URI that identifies a resource by name in a particular namespace.

* Syntax of Uniform Resource Identifiers (URIs)

  * Scheme or protocol - http:// is the protocol. It indicates which protocol the browser must use. Usually it is the HTTP protocol or its secured version, HTTPS. The Web requires one of these two, but browsers also know how to handle other protocols such as mailto: (to open a mail client) or ftp: to handle a file transfer, so don't be surprised if you see such protocols. Common schemes are:
        Scheme	            Description
        data	              Data URLs
        file	              Host-specific file names
        ftp	                File Transfer Protocol
        http/https	        Hyper text transfer protocol (Secure)
        javascript	        URL-embedded JavaScript code
        mailto	            Electronic mail address
        ssh	                Secure shell
        tel	                telephone
        urn	                Uniform Resource Names
        view-source	        Source code of the resource
        ws/wss	            WebSocket connections (Secure)

  * Authority - www.example.com is the domain name or authority that governs the namespace. It indicates which Web server is being requested. Alternatively, it is possible to directly use an IP address, but because it is less convenient, it is not often used on the Web.

  * Port - :80 is the port in this instance. It indicates the technical "gate" used to access the resources on the web server. It is usually omitted if the web server uses the standard ports of the HTTP protocol (80 for HTTP and 443 for HTTPS) to grant access to its resources. Otherwise, it is mandatory.

  * Path - /path/to/myfile.html is the path to the resource on the Web server. In the early days of the Web, a path like this represented a physical file location on the Web server. Nowadays, it is mostly an abstraction handled by Web servers without any physical reality.

  * Query - ?key1=value1&key2=value2 are extra parameters provided to the Web server. Those parameters are a list of key/value pairs separated with the & symbol. The Web server can use those parameters to do extra stuff before returning the resource to the user. Each Web server has its own rules regarding parameters, and the only reliable way to know how a specific Web server is handling parameters is by asking the Web server owner.

  * Fragment -


* Usage notes
        * When using URLs in HTML content, you should generally only use a few of these URL schemes. When referring to subresources — that is, files that are being loaded as part of a larger document — you should only use the HTTP and HTTPS schemes. Increasingly, browsers are removing support for using FTP to load subresources, for security reasons.
        * FTP is still acceptable at the top level (such as typed directly into the browser's URL bar, or the target of a link), although some browsers may delegate loading FTP content to another application
        * 
                        https://developer.mozilla.org/en-US/docs/Learn
                        tel:+1-816-555-1212
                        git@github.com:mdn/browser-compat-data.git
                        ftp://example.org/resource.txt
                        urn:isbn:9780141036144
                        mailto:help@supercyberhelpdesk.info


2) Data URLs -
     * Data URLs, URLs prefixed with the data: scheme, allow content creators to embed small files inline in documents. They were formerly known as "data URIs" until that name was retired by the WHATWG.
     * Syntax -
                    Data URLs are composed of four parts: a prefix (data:), a MIME type indicating the type of data, an optional base64 token if non-textual, and the data itself:
                                   data:[<mediatype>][;base64],<data>
     * The mediatype is a MIME type string, such as 'image/jpeg' for a JPEG image file. If omitted, defaults to text/plain;charset=US-ASCII
     * If the data contains characters defined in RFC 3986 as reserved characters, or contains space characters, newline characters, or other non-printing characters, those characters must be percent-encoded.
     * A few examples:
               data:,Hello%2C%20World%21
               The text/plain data Hello, World!. Note how the comma is percent-encoded as %2C, and the space character as %20.
               
               data:text/plain;base64,SGVsbG8sIFdvcmxkIQ==
               base64-encoded version of the above
               
               data:text/html,%3Ch1%3EHello%2C%20World%21%3C%2Fh1%3E
               An HTML document with <h1>Hello, World!</h1>
               
               data:text/html,%3Cscript%3Ealert%28%27hi%27%29%3B%3C%2Fscript%3E
               An HTML document with <script>alert('hi');</script> that executes a JavaScript alert. Note that the closing script tag is required.

3) Introduction to MIME types -
4) Common MIME types -

5) Choosing between www and non-www URLs -
     * What are domain names?
          * In an HTTP URL, the first substring that follows the initial http:// or https:// is called the domain name. This domain name is hosted on a server where the document resides.
          * A server isn't necessarily a physical machine: several servers can reside on the same physical machine. Or, one server can be handled by several machines, cooperating to produce the answer or balancing the load of the requests between them. The key point is that semantically one domain name represents one single server.

     * So, do I have to choose one or the other for my website?
          * Yes, you need to choose one and stick with it. The choice of which one to have as your canonical location is yours, but if you choose one, stick with it. It will make your website appear more consistent to your users and to search engines. This includes always linking to the chosen domain (which shouldn't be hard if you're using relative URLs in your website) and always sharing links (by email/social networks, etc.) to the same domain.

          * No, you can have two. What is important is that you are coherent and consistent with which one is the official domain. This official domain is called the canonical name. All your absolute links should use it. But even so, you can still have the other domain working: HTTP allows two techniques so that it is clear for your users, or search engines, which domain is the canonical one, while still allowing the non-canonical domain to work and provide the expected pages.

     * Techniques for canonical URLs
          * Using HTTP 301 redirects
               In this case, you need to configure the server receiving the HTTP requests (which is most likely the same for 'www' and 'non-www' URLs) to respond with an adequate HTTP 301 response to any request to the non-canonical domain. This will redirect the browser trying to access the non-canonical URLs to their canonical equivalent. For example, if you've chosen to use 'non-www' URLs as the canonical type, you should redirect all 'www' URLs to their equivalent URL without the 'www'.
               * Example:          
                    A server receives a request for http://www.example.org/whaddup (when the canonical domain is example.org).
                    The server answers with a code 301 with the Location header Location: http://example.org/whaddup.
                    The client issues a request to the location under the canonical domain: http://example.org/whaddup.

          * Using <link rel="canonical"> - 
               * It is possible to add a special HTML <link> element to a page to indicate what the canonical address of a page is. This has no impact on the human reader of the page, but tells search engine crawlers where the page actually lives. This way, search engines don't index the same page several times, potentially leading to it being considered as duplicate content or spam, and even removing or lowering your page from the search engine result pages.
               * When adding such a tag, you serve the same content for both domains, telling search engines which URL is canonical. In the previous example, http://www.example.org/whaddup would serve the same content as http://example.org/whaddup, but with an additional <link> element in the head:
                         <link href="http://example.org/whaddup" rel="canonical" />

     * Make your page work for both - With these techniques, you can configure your server to respond correctly for both, the www-prefixed and the non-www-prefixed domains. It is good advice to do this since you can't predict which URL users will type in their browser's URL bar. It is a matter of choosing which type you want to use as your canonical location, then redirecting the other type to it.


----------------------
HTTP Guide -

1) An overview of HTTP -
     * HTTP is a protocol for fetching resources such as HTML documents. It is the foundation of any data exchange on the Web and it is a client-server protocol, which means requests are initiated by the recipient, usually the Web browser. A complete document is typically constructed from resources such as text content, layout instructions, images, videos, scripts, and more.

     * Clients and servers communicate by exchanging individual messages (as opposed to a stream of data). The messages sent by the client are called requests and the messages sent by the server as an answer are called responses.
     * Designed in the early 1990s, HTTP is an extensible protocol which has evolved over time. It is an application layer protocol that is sent over TCP, or over a TLS-encrypted TCP connection, though any reliable transport protocol could theoretically be used. Due to its extensibility, it is used to not only fetch hypertext documents, but also images and videos or to post content to servers, like with HTML form results. HTTP can also be used to fetch parts of documents to update Web pages on demand.

     * Components of HTTP-based systems -
          * HTTP is a client-server protocol: requests are sent by one entity, the user-agent (or a proxy on behalf of it). Most of the time the user-agent is a Web browser, but it can be anything, for example, a robot that crawls the Web to populate and maintain a search engine index.
          * Each individual request is sent to a server, which handles it and provides an answer called the response. Between the client and the server there are numerous entities, collectively called proxies, which perform different operations and act as gateways or caches.
          * In reality, there are more computers between a browser and the server handling the request: there are routers, modems, and more. Thanks to the layered design of the Web, these are hidden in the network and transport layers. HTTP is on top, at the application layer. Although important for diagnosing network problems, the underlying layers are mostly irrelevant to the description of HTTP.

     * Proxies -
          * Between the Web browser and the server, numerous computers and machines relay the HTTP messages. Due to the layered structure of the Web stack, most of these operate at the transport, network or physical levels, becoming transparent at the HTTP layer and potentially having a significant impact on performance. Those operating at the application layers are generally called proxies. These can be transparent, forwarding on the requests they receive without altering them in any way, or non-transparent, in which case they will change the request in some way before passing it along to the server. Proxies may perform numerous functions:
               caching (the cache can be public or private, like the browser cache)
               filtering (like an antivirus scan or parental controls)
               load balancing (to allow multiple servers to serve different requests)
               authentication (to control access to different resources)
               logging (allowing the storage of historical information)


     * Basic aspects of HTTP
          * HTTP is simple - HTTP is generally designed to be simple and human-readable, even with the added complexity introduced in HTTP/2 by encapsulating HTTP messages into frames. HTTP messages can be read and understood by humans, providing easier testing for developers, and reduced complexity for newcomers.
          * HTTP is extensible - Introduced in HTTP/1.0, HTTP headers make this protocol easy to extend and experiment with. New functionality can even be introduced by a simple agreement between a client and a server about a new header's semantics.
          * HTTP is stateless, but not sessionless - HTTP is stateless: there is no link between two requests being successively carried out on the same connection. This immediately has the prospect of being problematic for users attempting to interact with certain pages coherently, for example, using e-commerce shopping baskets. But while the core of HTTP itself is stateless, HTTP cookies allow the use of stateful sessions. Using header extensibility, HTTP Cookies are added to the workflow, allowing session creation on each HTTP request to share the same context, or the same state.
          * HTTP and connections - 
                    * A connection is controlled at the transport layer, and therefore fundamentally out of scope for HTTP. HTTP doesn't require the underlying transport protocol to be connection-based; it only requires it to be reliable, or not lose messages (at minimum, presenting an error in such cases). Among the two most common transport protocols on the Internet, TCP is reliable and UDP isn't. HTTP therefore relies on the TCP standard, which is connection-based.
                    * Before a client and server can exchange an HTTP request/response pair, they must establish a TCP connection, a process which requires several round-trips. The default behavior of HTTP/1.0 is to open a separate TCP connection for each HTTP request/response pair. This is less efficient than sharing a single TCP connection when multiple requests are sent in close succession.
                    * In order to mitigate this flaw, HTTP/1.1 introduced pipelining (which proved difficult to implement) and persistent connections: the underlying TCP connection can be partially controlled using the Connection header. HTTP/2 went a step further by multiplexing messages over a single connection, helping keep the connection warm and more efficient.
                    * Experiments are in progress to design a better transport protocol more suited to HTTP. For example, Google is experimenting with QUIC which builds on UDP to provide a more reliable and efficient transport protocol.


     * What can be controlled by HTTP -
          * This extensible nature of HTTP has, over time, allowed for more control and functionality of the Web. Cache and authentication methods were functions handled early in HTTP history. The ability to relax the origin constraint, by contrast, was only added in the 2010s.
          * Here is a list of common features controllable with HTTP:
                    * Caching: How documents are cached can be controlled by HTTP. The server can instruct proxies and clients about what to cache and for how long. The client can instruct intermediate cache proxies to ignore the stored document.
                    * Relaxing the origin constraint: To prevent snooping and other privacy invasions, Web browsers enforce strict separation between websites. Only pages from the same origin can access all the information of a Web page. Though such a constraint is a burden to the server, HTTP headers can relax this strict separation on the server side, allowing a document to become a patchwork of information sourced from different domains; there could even be security-related reasons to do so.
                    * Authentication: Some pages may be protected so that only specific users can access them. Basic authentication may be provided by HTTP, either using the WWW-Authenticate and similar headers, or by setting a specific session using HTTP cookies.
                    * Proxy and tunneling: Servers or clients are often located on intranets and hide their true IP address from other computers. HTTP requests then go through proxies to cross this network barrier. Not all proxies are HTTP proxies. The SOCKS protocol, for example, operates at a lower level. Other protocols, like ftp, can be handled by these proxies.
                    * Sessions: Using HTTP cookies allows you to link requests with the state of the server. This creates sessions, despite basic HTTP being a state-less protocol. This is useful not only for e-commerce shopping baskets, but also for any site allowing user configuration of the output.


     * HTTP flow -
          * When a client wants to communicate with a server, either the final server or an intermediate proxy, it performs the following steps:
               * Open a TCP connection: The TCP connection is used to send a request, or several, and receive an answer. The client may open a new connection, reuse an existing connection, or open several TCP connections to the servers.
               * Send an HTTP message: HTTP messages (before HTTP/2) are human-readable. With HTTP/2, these simple messages are encapsulated in frames, making them impossible to read directly, but the principle remains the same. For example:
               http - 
                    GET / HTTP/1.1
                    Host: developer.mozilla.org
                    Accept-Language: fr
               
               Read the response sent by the server, such as:
               http
                         HTTP/1.1 200 OK
                         Date: Sat, 09 Oct 2010 14:28:02 GMT
                         Server: Apache
                         Last-Modified: Tue, 01 Dec 2009 20:18:22 GMT
                         ETag: "51142bc1-7449-479b075b2891b"
                         Accept-Ranges: bytes
                         Content-Length: 29769
                         Content-Type: text/html     
                         <!DOCTYPE html>… (here come the 29769 bytes of the requested web page)
               * Close or reuse the connection for further requests.

               * If HTTP pipelining is activated, several requests can be sent without waiting for the first response to be fully received. HTTP pipelining has proven difficult to implement in existing networks, where old pieces of software coexist with modern versions. HTTP pipelining has been superseded in HTTP/2 with more robust multiplexing requests within a frame.

     * HTTP Messages
          HTTP messages, as defined in HTTP/1.1 and earlier, are human-readable. In HTTP/2, these messages are embedded into a binary structure, a frame, allowing optimizations like compression of headers and multiplexing. Even if only part of the original HTTP message is sent in this version of HTTP, the semantics of each message is unchanged and the client reconstitutes (virtually) the original HTTP/1.1 request. It is therefore useful to comprehend HTTP/2 messages in the HTTP/1.1 format.
          
          There are two types of HTTP messages, requests and responses, each with its own format.
               * Request - 
                              GET / HTTP/1.1
                              Host: developer.mozilla.org
                              Accept-Language: fr
               * Requests consist of the following elements:
                    * An HTTP method, usually a verb like GET, POST, or a noun like OPTIONS or HEAD that defines the operation the client wants to perform. Typically, a client wants to fetch a resource (using GET) or post the value of an HTML form (using POST), though more operations may be needed in other cases.
                    * The path of the resource to fetch; the URL of the resource stripped from elements that are obvious from the context, for example without the protocol (http://), the domain (here, developer.mozilla.org), or the TCP port (here, 80).
                    * The version of the HTTP protocol.
                    * Optional headers that convey additional information for the servers.
                    * A body, for some methods like POST, similar to those in responses, which contain the resource sent.

               * Response - 
                    HTTP/1.1 200 OK
                    Date: Sat, 09 Oct 2010 14:28:02 GMT
                    Server: Apache
                    Last-Modified: Tue, 01 Dec 2009 20:18:22 GMT
                    ETag: "51142bc1-7449-479b075b2891b"
                    Accept-Ranges: bytes
                    Content-Length: 29769
                    Content-Type: text/html
                    
                    <!DOCTYPE html>… (here come the 29769 bytes of the requested web page)

               * Responses consist of the following elements:
                         The version of the HTTP protocol they follow.
                         A status code, indicating if the request was successful or not, and why.
                         A status message, a non-authoritative short description of the status code.
                         HTTP headers, like those for requests.
                         Optionally, a body containing the fetched resource.

2) Evolution of HTTP -

3) HTTP Messages -

4) A typical HTTP session -

5) connection management in HTTP/1.x

6) Protocol upgrade mechanism
